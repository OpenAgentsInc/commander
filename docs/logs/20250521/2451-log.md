# Fix for AgentLanguageModel Service Not Found Error

## Issue
Application was failing to start with error: `(FiberFailure) Error: Service not found: AgentLanguageModel (defined at http://localhost:5173/src/services/ai/core/AgentLanguageModel.ts:2:43)`

## Root Cause Analysis
The issue is in `OllamaAgentLanguageModelLive.ts`. The simplified provider approach with manual construction of a mock provider object and `as any` type assertions doesn't properly integrate with Effect's runtime context system. This causes the `AgentLanguageModel` tag not to be correctly registered in the application's Effect context.

For OpenAI-compatible providers like the Ollama adapter, we need to use the standard `@effect/ai` patterns by properly using the `OpenAiLanguageModel.model(...)` factory from `@effect/ai-openai`.

## Implementation

I'm refactoring `src/services/ai/providers/ollama/OllamaAgentLanguageModelLive.ts` to use the correct Effect patterns:

1. Use `OpenAiLanguageModel.model(modelName)` to create the proper Effect-based model
2. Properly provide the Ollama adapter client to this model
3. Correctly yield the provider from the AiModel instance
4. Return a proper AgentLanguageModel implementation that uses the provider

The key insight is understanding the two-step process: first get an AiModel from `OpenAiLanguageModel.model()`, then yield that to get the actual Provider instance.

## Working through the fix now